{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error, mean_absolute_percentage_error, f1_score\n",
    "from scipy.stats import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Prediction Results\n",
    "pred_low  = pd.read_csv(\"08_results_models/Prediction_Low.csv\")\n",
    "pred_mid  = pd.read_csv(\"08_results_models/Prediction_Mid.csv\")\n",
    "pred_high = pd.read_csv(\"08_results_models/Prediction_High.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52368"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine 2_stage results\n",
    "combine_2stage = pd.concat([pred_low, pred_mid, pred_high], axis=0).sort_values(by='row_id')\n",
    "len(combine_2stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Price columns\n",
    "cols_to_drop = [\n",
    "    'log_odometer', 'log_car_age', 'log_miles_age',\n",
    "    'log_state_freq', 'log_model_freq', 'manufacturer_marketcap',\n",
    "    'condition_grouped', 'cylinders_cat', 'fuel',\n",
    "    'title_status', 'transmission', 'drive',\n",
    "    'type_grouped'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine All predictions into 2_stage predictions\n",
    "def final_pred(row):\n",
    "    if row['segment_pred'] == 1:\n",
    "        return row['low_pred_log'], row['low_pred']\n",
    "    elif row['segment_pred'] == 2:\n",
    "        return row['mid_pred_log'], row['mid_pred']\n",
    "    elif row['segment_pred'] == 3:\n",
    "        return row['high_pred_log'], row['high_pred']\n",
    "    \n",
    "combine_2stage[['2stage_pred_log', '2stage_pred']] = combine_2stage.apply(lambda row: pd.Series(final_pred(row)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop seperate predictions\n",
    "combine_2stage.drop(columns=[\n",
    "    'low_pred_log', 'low_pred',\n",
    "    'mid_pred_log', 'mid_pred',\n",
    "    'high_pred_log', 'high_pred'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Non important features\n",
    "combine_2stage.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with 1 stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Predictions 1-stage + Delete non important\n",
    "pred_1stage  = pd.read_csv(\"08_results_models/Prediction_1stage.csv\")\n",
    "pred_1stage.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Results\n",
    "merged_results = combine_2stage.merge(pred_1stage, on='row_id', how='left')\n",
    "merged_results = merged_results.sort_values(by='row_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Predictions Dummy + Delete non important\n",
    "pred_dummy = pd.read_csv(\"Prediction_Dummy.csv\")\n",
    "pred_dummy.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Results\n",
    "merged_results = merged_results.merge(pred_dummy, on='row_id', how='left')\n",
    "merged_results = merged_results.sort_values(by='row_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Combined Results \n",
    "merged_results.to_csv(\"08_results_models/Results_All_Models.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Feature Importance Data\n",
    "importance_class  = pd.read_csv(\"08_feature_importance/Feature_Importance_Classification.csv\")\n",
    "importance_1stage = pd.read_csv(\"08_feature_importance/Feature_Importance_Regression.csv\")\n",
    "importance_low    = pd.read_csv(\"08_feature_importance/Feature_Importance_Low.csv\")\n",
    "importance_mid    = pd.read_csv(\"08_feature_importance/Feature_Importance_Mid.csv\")\n",
    "importance_high   = pd.read_csv(\"08_feature_importance/Feature_Importance_High.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save one DF with all combined Feature Importance sorted on mean_importance\n",
    "feature_importance = importance_class.merge(importance_1stage, on='feature', how='outer')\n",
    "feature_importance = feature_importance.merge(importance_low, on='feature', how='outer')\n",
    "feature_importance = feature_importance.merge(importance_mid, on='feature', how='outer')\n",
    "feature_importance = feature_importance.merge(importance_high, on='feature', how='outer')\n",
    "feature_importance['mean_importance'] = feature_importance[['importance_1stage', 'importance_low', 'importance_mid', 'importance_high']].mean(axis=1)\n",
    "feature_importance = feature_importance.sort_values(by='mean_importance', ascending=False)\n",
    "feature_importance.to_csv('08_feature_importance/Feature_Importance_Combined.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
